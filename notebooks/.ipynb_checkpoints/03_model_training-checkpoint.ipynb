{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd09e3c-59e3-4203-9304-49414bc1c56a",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation\n",
    "\n",
    "In this notebook, we train and evaluate multiple classifiers on the preprocessed Bot-IoT and TON-IoT Modbus datasets.  \n",
    "\n",
    "We will train:\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- LightGBM\n",
    "\n",
    "We will evaluate models using:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "- Confusion Matrix\n",
    "\n",
    "Finally, we will compare all models in a summary table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af3c957-c3d0-4603-9d93-6b937f9bd67b",
   "metadata": {},
   "source": [
    "## Step 2: Import Required Libraries\n",
    "\n",
    "We need libraries for:\n",
    "- Data manipulation\n",
    "- Model training\n",
    "- Metrics evaluation\n",
    "- Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1013aa01-5bdc-4bca-9c4d-56ce701cb061",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib\n",
    "!pip install xgboost lightgbm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6405dabf-7765-4d77-95a6-9d09e1cbf580",
   "metadata": {},
   "source": [
    "##  Load Preprocessed Dataset Splits\n",
    "\n",
    "We will load the preprocessed `train` and `test` splits for both datasets (`Bot-IoT` and `TON-IoT-Modbus`) saved as `.npy` files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21bd80a-d163-42e3-adc4-06cf50306949",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_dir = r\"C:\\Users\\User\\IIoT_IDS_Project\\data\\splits\"\n",
    "\n",
    "datasets = {\n",
    "    \"bot-iot\": {\n",
    "        \"X_train\": os.path.join(splits_dir, \"X_train_bot-iot.npy\"),\n",
    "        \"X_test\": os.path.join(splits_dir, \"X_test_bot-iot.npy\"),\n",
    "        \"y_train\": os.path.join(splits_dir, \"y_train_bot-iot.npy\"),\n",
    "        \"y_test\": os.path.join(splits_dir, \"y_test_bot-iot.npy\")\n",
    "    },\n",
    "    \"ton-iot-modbus\": {\n",
    "        \"X_train\": os.path.join(splits_dir, \"X_train_ton-iot-modbus.npy\"),\n",
    "        \"X_test\": os.path.join(splits_dir, \"X_test_ton-iot-modbus.npy\"),\n",
    "        \"y_train\": os.path.join(splits_dir, \"y_train_ton-iot-modbus.npy\"),\n",
    "        \"y_test\": os.path.join(splits_dir, \"y_test_ton-iot-modbus.npy\")\n",
    "    }\n",
    "}\n",
    "\n",
    "# Test load one dataset\n",
    "X_train_test = np.load(datasets[\"bot-iot\"][\"X_train\"])\n",
    "y_train_test = np.load(datasets[\"bot-iot\"][\"y_train\"])\n",
    "print(f\"Bot-IoT X_train shape: {X_train_test.shape}, y_train shape: {y_train_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f9448a-2fdc-4cab-911e-d37143eee61c",
   "metadata": {},
   "source": [
    "## Define Models\n",
    "\n",
    "We define three classifiers to train:\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- LightGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24df2755-47a7-476f-ab7c-f8ccc20d0f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162051ef-6ae9-419b-b104-0bd54bf73617",
   "metadata": {},
   "source": [
    "## Train and Evaluate Each Model\n",
    "\n",
    "For each dataset and each model:\n",
    "1. Train the model on training data\n",
    "2. Predict on test data\n",
    "3. Calculate metrics: Accuracy, Precision, Recall, F1-score\n",
    "4. Display Classification Report\n",
    "5. Plot Confusion Matrix\n",
    "6. Save trained model\n",
    "7. Store metrics for summary table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f75754-5a40-437d-8874-c7ce1339b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_results = []\n",
    "\n",
    "for dataset_name, paths in datasets.items():\n",
    "    print(f\"\\n\\n=== Dataset: {dataset_name} ===\")\n",
    "\n",
    "    # Load preprocessed splits\n",
    "    X_train = np.load(paths[\"X_train\"])\n",
    "    X_test = np.load(paths[\"X_test\"])\n",
    "    y_train = np.load(paths[\"y_train\"])\n",
    "    y_test = np.load(paths[\"y_test\"])\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\n--- Model: {model_name} ---\")\n",
    "\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Metrics\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "        print(f\"Accuracy:  {acc:.4f}\")\n",
    "        print(f\"Precision: {prec:.4f}\")\n",
    "        print(f\"Recall:    {rec:.4f}\")\n",
    "        print(f\"F1-score:  {f1:.4f}\")\n",
    "\n",
    "        # Classification report\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(5,4))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title(f\"{dataset_name} - {model_name} Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.show()\n",
    "\n",
    "        # Save model\n",
    "        model_dir = os.path.join(r\"C:\\Users\\User\\IIoT_IDS_Project\\models\")\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        joblib.dump(model, os.path.join(model_dir, f\"{dataset_name}_{model_name}.joblib\"))\n",
    "\n",
    "        # Append to summary\n",
    "        summary_results.append({\n",
    "            \"Dataset\": dataset_name,\n",
    "            \"Model\": model_name,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1-score\": f1\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7e752-edbd-4ca0-ac87-a65732e8f3f2",
   "metadata": {},
   "source": [
    "## Summary Table\n",
    "\n",
    "We display a summary table of metrics for all models and datasets for easy comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e504ce60-69cc-48d9-b79a-ed09ef9d36b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(summary_results)\n",
    "display(summary_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
